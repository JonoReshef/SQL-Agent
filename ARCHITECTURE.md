# WestBrand Email Analysis - Architectural Overview

## Executive Summary

A test-driven Python system for analyzing Outlook emails to extract product information, match against inventory using **database-driven hierarchical filtering**, and generate comprehensive 5-sheet Excel reports with full database persistence. The system processes individual `.msg` files (no threading), uses Azure OpenAI (GPT-5) for intelligent extraction, PostgreSQL 17 with **thread_hash** as primary key for deduplication, and is orchestrated via LangGraph workflows. Additionally, a **SQL Chat Workflow** provides natural language query access to the database via FastAPI REST API.

**Key Features**:

- Synchronous email analysis with LLM extraction
- PostgreSQL database with thread_hash PKs and content_hash for all records
- Database-driven hierarchical matching (10-100x faster than linear scan)
- Fuzzy property matching using rapidfuzz
- Multi-sheet Excel reports (3 or 5 sheets based on --match flag)
- **Natural language SQL chat interface with conversation persistence**
- **FastAPI REST API with streaming support**
- Production-ready deployment with Docker Compose

## Core Architectural Principles

### 1. Simplicity First

- **Synchronous Processing**: No async/await complexity
- **Single Email Analysis**: Each `.msg` file processed independently
- **No Thread Reconstruction**: Explicitly avoided - too complex and outside scope
- **Clear Data Flow**: Input â†’ Process â†’ Output

### 2. Test-Driven Development

- **Tests Before Code**: Write comprehensive tests first
- **Continuous Validation**: Run tests frequently during development
- **26/26 Tests Passing**: Strong foundation established
- **Pytest Framework**: Modern, well-documented testing

### 3. Type Safety

- **Pydantic v2**: All data structures typed and validated
- **Compile-time Checks**: Catch errors early
- **Self-documenting**: Models serve as API documentation

### 4. Database-Backed Persistence

- **PostgreSQL with pgvector**: Relational database for structured data
- **Foreign Key Relationships**: Proper data integrity
- **Upsert Operations**: Idempotent database writes
- **Optional Database**: System works without database if needed

## System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     CONFIGURATION LAYER                         â”‚
â”‚                   (products_config.yaml)                        â”‚
â”‚                                                                 â”‚
â”‚  â€¢ Product Definitions (Fasteners, Threaded Rod, etc.)         â”‚
â”‚  â€¢ Properties to Extract (grade, size, material, etc.)         â”‚
â”‚  â€¢ Extraction Rules (patterns, formats)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     DATABASE LAYER                              â”‚
â”‚                  (PostgreSQL 17 + pgvector)                     â”‚
â”‚                                                                 â”‚
â”‚  Tables:                                                        â”‚
â”‚  â€¢ emails_processed                                            â”‚
â”‚    - thread_hash VARCHAR(64) PRIMARY KEY (SHA256 content hash) â”‚
â”‚    - file_path, subject, sender, date_sent                     â”‚
â”‚  â€¢ product_mentions                                            â”‚
â”‚    - id SERIAL PRIMARY KEY                                      â”‚
â”‚    - email_thread_hash FK â†’ emails_processed.thread_hash       â”‚
â”‚    - content_hash VARCHAR(64) (for change detection)           â”‚
â”‚  â€¢ inventory_items                                             â”‚
â”‚    - id SERIAL PRIMARY KEY                                      â”‚
â”‚    - item_number VARCHAR(100) UNIQUE                           â”‚
â”‚    - content_hash VARCHAR(64) (for change detection)           â”‚
â”‚  â€¢ inventory_matches                                           â”‚
â”‚    - id SERIAL PRIMARY KEY                                      â”‚
â”‚    - product_mention_id FK â†’ product_mentions.id              â”‚
â”‚    - inventory_item_id FK â†’ inventory_items.id                â”‚
â”‚    - content_hash VARCHAR(64) (for change detection)           â”‚
â”‚  â€¢ match_review_flags                                          â”‚
â”‚    - id SERIAL PRIMARY KEY                                      â”‚
â”‚    - product_mention_id FK â†’ product_mentions.id              â”‚
â”‚    - content_hash VARCHAR(64) (for change detection)           â”‚
â”‚  â€¢ checkpoints (LangGraph conversation persistence)            â”‚
â”‚    - thread_id, checkpoint_id, parent_checkpoint_id            â”‚
â”‚    - checkpoint (JSONB), metadata (JSONB)                      â”‚
â”‚                                                                 â”‚
â”‚  Features:                                                      â”‚
â”‚  â€¢ Foreign key constraints with CASCADE deletes                 â”‚
â”‚  â€¢ Indexes on all FKs and content_hash columns                  â”‚
â”‚  â€¢ Upsert operations based on natural keys                      â”‚
â”‚  â€¢ Content hashing for intelligent change detection             â”‚
â”‚  â€¢ Conversation state persistence for chat workflow             â”‚
â”‚  â€¢ Docker Compose for easy deployment                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“                    â†“
              EMAIL ANALYSIS           SQL CHAT WORKFLOW
                 WORKFLOW             (src/chat_workflow/)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       INPUT PIPELINE                            â”‚
â”‚                                                                 â”‚
â”‚  Directory Scanner â†’ .msg File Discovery â†’ Email Parser         â”‚
â”‚                                                                 â”‚
â”‚  âœ… Implemented:                                                â”‚
â”‚    â€¢ read_msg_file(path) - Parse single email                  â”‚
â”‚    â€¢ read_msg_files_from_directory(dir) - Batch parse          â”‚
â”‚    â€¢ Extract metadata (subject, sender, recipients, date)      â”‚
â”‚    â€¢ Extract body (HTML, RTF, plain text)                      â”‚
â”‚    â€¢ List attachments                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  PREPROCESSING PIPELINE                         â”‚
â”‚                                                                 â”‚
â”‚  HTML Stripping â†’ Signature Removal â†’ Text Cleaning            â”‚
â”‚                                                                 â”‚
â”‚  âœ… Implemented:                                                â”‚
â”‚    â€¢ strip_html_tags() - BeautifulSoup HTML parsing            â”‚
â”‚    â€¢ clean_signature() - Remove footers, quotes, separators    â”‚
â”‚    â€¢ Preserve core email content                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  LANGGRAPH WORKFLOW (Synchronous)               â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚INGESTION â”‚â†’ â”‚EXTRACTION â”‚â†’ â”‚MATCHING*â”‚â†’ â”‚PERSISTENCEâ”‚  â”‚
â”‚  â”‚   NODE   â”‚  â”‚   NODE    â”‚  â”‚  NODE   â”‚  â”‚   NODE     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                    *conditional with --match   â”‚
â”‚                                           â†“                  â”‚
â”‚                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚                                    â”‚ REPORTING â”‚       â”‚
â”‚                                    â”‚   NODE    â”‚       â”‚
â”‚                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                              â”‚
â”‚  Node Locations (src/analysis_workflow/nodes/):               â”‚
â”‚  â€¢ ingestion/ingestion.py - Load & parse .msg files          â”‚
â”‚  â€¢ extraction/extraction.py - LLM product extraction         â”‚
â”‚  â€¢ matching/matching.py - Hierarchical inventory matching    â”‚
â”‚    â””â”€ utils/hierarchy.py - Property hierarchies           â”‚
â”‚    â””â”€ utils/filtering.py - Database-driven filtering     â”‚
â”‚    â””â”€ utils/matcher.py - Match scoring & ranking         â”‚
â”‚    â””â”€ utils/normalizer.py - Property normalization       â”‚
â”‚  â€¢ persistence/persistence.py - Database storage with upsert â”‚
â”‚  â€¢ reporting/reporting.py - 5-sheet Excel generation         â”‚
â”‚                                                              â”‚
â”‚  State Machine (Pydantic BaseModel in src/models/workflow.py):â”‚
â”‚  {                                                            â”‚
â”‚    input_directory: str,                                      â”‚
â”‚    emails: List[Email] = [],                                  â”‚
â”‚    extracted_products: List[ProductMention] = [],             â”‚
â”‚    analytics: List[ProductAnalytics] = [],                    â”‚
â”‚    matching_enabled: bool = False,                            â”‚
â”‚    product_matches: List[InventoryMatch] = [],                â”‚
â”‚    review_flags: List[ReviewFlag] = [],                       â”‚
â”‚    report_path: str = "",                                       â”‚
â”‚    errors: List[str] = []  # Auto-initialized                 â”‚
â”‚  }                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚  â”‚INGESTION â”‚â†’ â”‚EXTRACTION â”‚â†’ â”‚MATCHING â”‚â†’ â”‚PERSISTENCE  â”‚â†’ â”‚REPORTING â”‚â”‚
â”‚  â”‚   NODE   â”‚  â”‚   NODE    â”‚  â”‚  NODE*  â”‚  â”‚   NODE      â”‚  â”‚  NODE    â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                    *optional with --match flag             â”‚
â”‚                                                                 â”‚
â”‚  Ingestion:           Extraction:           Matching:           â”‚
â”‚  â€¢ Load .msg files    â€¢ Clean body text    â€¢ Load inventory    â”‚
â”‚  â€¢ Parse metadata     â€¢ LLM invoke()       â€¢ Fuzzy match props â”‚
â”‚  â€¢ Initial validation â€¢ Extract products   â€¢ Score confidence  â”‚
â”‚                       â€¢ Validate results    â€¢ Generate flags    â”‚
â”‚                                                                 â”‚
â”‚  Persistence:         Reporting:                                â”‚
â”‚  â€¢ Store emails       â€¢ Aggregate data                          â”‚
â”‚  â€¢ Store products     â€¢ Format tables                           â”‚
â”‚  â€¢ Store matches      â€¢ Add match/flag sheets                   â”‚
â”‚  â€¢ Store flags        â€¢ Generate Excel                          â”‚
â”‚                                                                 â”‚
â”‚  State Machine (Pydantic BaseModel):                            â”‚
â”‚  {                                                              â”‚
â”‚    input_directory: str,                                        â”‚
â”‚    emails: List[Email] = [],                                    â”‚
â”‚    extracted_products: List[ProductMention] = [],               â”‚
â”‚    analytics: List[ProductAnalytics] = [],                      â”‚
â”‚    inventory_items: List[InventoryItem] = [],                   â”‚
â”‚    product_matches: Dict[str, List[InventoryMatch]] = {},       â”‚
â”‚    review_flags: List[ReviewFlag] = [],                         â”‚
â”‚    report_path: str = "",                                       â”‚
â”‚    matching_enabled: bool = False,                              â”‚
â”‚    errors: List[str] = []  # Auto-initialized                   â”‚
â”‚  }                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 AI EXTRACTION LAYER                             â”‚
â”‚                  (Azure OpenAI GPT-5)                           â”‚
â”‚                                                                 â”‚
â”‚  Prompt Engineering:                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ System: You are analyzing industrial product emails.    â”‚  â”‚
â”‚  â”‚                                                          â”‚  â”‚
â”‚  â”‚ Extract:                                                 â”‚  â”‚
â”‚  â”‚ - Product names and categories                          â”‚  â”‚
â”‚  â”‚ - Properties (grade, size, material, finish, etc.)      â”‚  â”‚
â”‚  â”‚ - Quantities and units                                  â”‚  â”‚
â”‚  â”‚ - Context (quote request, order, inquiry)               â”‚  â”‚
â”‚  â”‚ - Dates mentioned                                       â”‚  â”‚
â”‚  â”‚                                                          â”‚  â”‚
â”‚  â”‚ Return: JSON array of products                          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                 â”‚
â”‚  LLM Configuration:                                             â”‚
â”‚  â€¢ Deployment: gpt-5                                            â”‚
â”‚  â€¢ API Version: 2024-08-01-preview                              â”‚
â”‚  â€¢ Temperature: 0 (deterministic extraction)                    â”‚
â”‚  â€¢ Reasoning effort: low                                        â”‚
â”‚  â€¢ Method: llm.invoke() - synchronous                           â”‚
â”‚  â€¢ Caching: Redis (localhost:6379)                              â”‚
â”‚  â€¢ Response: Structured JSON via with_structured_output()       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 INVENTORY MATCHING LAYER                        â”‚
â”‚          (Database-Driven Hierarchical Filtering)               â”‚
â”‚                                                                 â”‚
â”‚  Module: src/analysis_workflow/nodes/matching/utils/            â”‚
â”‚                                                                 â”‚
â”‚  Property Hierarchy (hierarchy.py):                             â”‚
â”‚  â€¢ Loads from config/products_config.yaml                       â”‚
â”‚  â€¢ Cached with @lru_cache for performance                      â”‚
â”‚  â€¢ Defines filter order: grade â†’ size â†’ length â†’ material    â”‚
â”‚                                                                 â”‚
â”‚  Database Filtering (filtering.py):                             â”‚
â”‚  â€¢ Progressive SQL queries on inventory_items table            â”‚
â”‚  â€¢ Filters by category first (exact match)                     â”‚
â”‚  â€¢ Then by properties in hierarchy order                       â”‚
â”‚  â€¢ Uses JSON property column with GIN index                    â”‚
â”‚  â€¢ Stops when result set < 10 items (graceful degradation)    â”‚
â”‚  â€¢ 10-100x faster than in-memory linear scan                   â”‚
â”‚                                                                 â”‚
â”‚  Property Normalizer (normalizer.py):                           â”‚
â€¢  Normalize values: "Gr 8" â†’ "8", "ss" â†’ "stainless steel"    â”‚
â”‚  â€¢ Fuzzy match with rapidfuzz (80% similarity threshold)       â”‚
â”‚  â€¢ Batch normalization for performance                         â”‚
â”‚  â€¢ Handle common variations and typos                          â”‚
â”‚                                                                 â”‚
â”‚  Product Matcher (matcher.py):                                  â”‚
â”‚  â€¢ Calls database filtering to get candidates                  â”‚
â”‚  â€¢ Scores remaining items with weighted properties            â”‚
â”‚  â€¢ 40% name + 20% category + 40% properties                    â”‚
â”‚  â€¢ Ranks by score, returns top N matches                       â”‚
â”‚  â€¢ Generates match reasoning explanations                      â”‚
â”‚                                                                 â”‚
â”‚  Review Flag Generation:                                        â”‚
â”‚  â€¢ INSUFFICIENT_DATA - No matches found                        â”‚
â”‚  â€¢ LOW_CONFIDENCE - Score < 0.7                                â”‚
â”‚  â€¢ AMBIGUOUS_MATCH - Top 2 scores within 0.1                  â”‚
â”‚  â€¢ MISSING_PROPERTIES - â‰¥2 properties not in inventory         â”‚
â”‚  â€¢ Priority-coded actions for each flag type                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚  â”‚ - Quantities and units                                  â”‚  â”‚
â”‚  â”‚ - Context (quote request, order, inquiry)               â”‚  â”‚
â”‚  â”‚ - Dates mentioned                                       â”‚  â”‚
â”‚  â”‚                                                          â”‚  â”‚
â”‚  â”‚ Return: JSON array of products                          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                 â”‚
â”‚  LLM Configuration:                                             â”‚
â”‚  â€¢ Deployment: gpt-4.1                                          â”‚
â”‚  â€¢ Temperature: 0 (deterministic extraction)                    â”‚
â”‚  â€¢ Method: llm.invoke() - synchronous                           â”‚
â”‚  â€¢ Response: Structured JSON                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    OUTPUT GENERATION                            â”‚
â”‚                  (Excel Multi-Sheet Report)                     â”‚
â”‚                                                                 â”‚
â”‚  Sheet 1: PRODUCT MENTIONS (Detailed)                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Product | Category | Properties | Quantity | Context  â”‚    â”‚
â”‚  â”‚ Date | Email Subject | Sender | Source File            â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                 â”‚
â”‚  Sheet 2: ANALYTICS (Aggregated)                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Product | Total Mentions | Date Range | Total Quantity â”‚    â”‚
â”‚  â”‚ Property Variations | Contexts | Unique Senders         â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                 â”‚
â”‚  Sheet 3: EMAIL SUMMARY                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Email File | Subject | Sender | Date | Product Count  â”‚    â”‚
â”‚  â”‚ Has Attachments | Parse Status                          â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                 â”‚
â”‚  Sheet 4: INVENTORY MATCHES (if --match enabled)                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Product | Inventory Item # | Description | Match Scoreâ”‚    â”‚
â”‚  â”‚ Rank | Matched Props | Missing Props | Reasoning      â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚  â€¢ Color-coded by score (green/yellow/orange)                  â”‚
â”‚  â€¢ NO MATCHES highlighted in red                                â”‚
â”‚                                                                 â”‚
â”‚  Sheet 5: REVIEW FLAGS (if --match enabled)                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Product | Issue Type | Match Count | Top Confidence   â”‚    â”‚
â”‚  â”‚ Reason | Action Needed                                  â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚  â€¢ Color-coded by priority (red/yellow/orange)                 â”‚
â”‚                                                                 â”‚
â”‚  Features:                                                      â”‚
â”‚  â€¢ Conditional formatting for easy reading                      â”‚
â”‚  â€¢ Frozen header rows                                           â”‚
â”‚  â€¢ Auto-filter columns                                          â”‚
â”‚  â€¢ Date formatting                                              â”‚
â”‚  â€¢ Pivot-table ready structure                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Data Models (Pydantic)

### Email Models

```python
EmailMetadata
  â€¢ message_id: Optional[str]
  â€¢ subject: str
  â€¢ sender: str
  â€¢ recipients: List[str]
  â€¢ cc: Optional[List[str]]
  â€¢ date: Optional[datetime]

Email
  â€¢ metadata: EmailMetadata
  â€¢ body: str
  â€¢ cleaned_body: Optional[str]
  â€¢ attachments: List[str]
  â€¢ file_path: Optional[str]
```

### Product Models

```python
ProductProperty
  â€¢ name: str (e.g., "grade", "size")
  â€¢ value: str
  â€¢ confidence: float (0.0 - 1.0)

ProductMention
  â€¢ exact_product_text: str  # Original text from email
  â€¢ product_name: str
  â€¢ product_category: str
  â€¢ properties: List[ProductProperty]
  â€¢ quantity: Optional[float]
  â€¢ unit: Optional[str]
  â€¢ context: str (quote_request, order, inquiry)
  â€¢ date_requested: Optional[str]
  â€¢ requestor: Optional[str]
  â€¢ email_subject: str
  â€¢ email_sender: str
  â€¢ email_file: Optional[str]

ProductAnalytics
  â€¢ product_name: str
  â€¢ product_category: str
  â€¢ total_mentions: int
  â€¢ first_mention: Optional[str]
  â€¢ last_mention: Optional[str]
  â€¢ total_quantity: Optional[float]
  â€¢ properties_summary: Dict[str, List[str]]
  â€¢ contexts: List[str]
  â€¢ people_involved: List[str]
```

### Inventory Models

```python
InventoryItem (extends ProductItem)
  â€¢ item_number: str  # Unique inventory ID
  â€¢ raw_description: str  # From Excel
  â€¢ exact_product_text: str
  â€¢ product_name: str
  â€¢ product_category: str
  â€¢ properties: List[ProductProperty]
  â€¢ parse_confidence: float
  â€¢ needs_manual_review: bool

InventoryMatch
  â€¢ inventory_item_number: str
  â€¢ inventory_description: str
  â€¢ match_score: float (0.0-1.0)
  â€¢ rank: int (1 = best match)
  â€¢ matched_properties: List[str]
  â€¢ missing_properties: List[str]
  â€¢ match_reasoning: str

ReviewFlag
  â€¢ product_text: str
  â€¢ product_name: str
  â€¢ product_category: str
  â€¢ issue_type: str  # INSUFFICIENT_DATA, LOW_CONFIDENCE, etc.
  â€¢ match_count: int
  â€¢ top_confidence: Optional[float]
  â€¢ reason: str
  â€¢ action_needed: str
```

### SQL Chat Models

```python
ChatState (LangGraph state)
  â€¢ messages: Annotated[List[BaseMessage], add]  # Conversation history
  â€¢ available_tables: List[str]  # Database table names
  â€¢ current_query: Optional[str]  # SQL being executed
  â€¢ query_result: Optional[str]  # Result from last query
  â€¢ error: Optional[str]  # Error messages
  â€¢ executed_queries: Annotated[List[QueryExecution], add]  # Query transparency
  â€¢ overall_summary: Optional[str]  # Search process summary

QueryExecution (for transparency)
  â€¢ query: str  # The actual SQL executed
  â€¢ query_explanation: QueryExplanation  # AI-generated explanation
  â€¢ raw_result: Optional[str]  # Query result

QueryExplanation
  â€¢ description: str  # One-line non-technical explanation
  â€¢ result_summary: str  # What was found (e.g., "Found 80 records")
```

## Technology Stack Justification

### Why These Libraries?

1. **PostgreSQL 17 + pgvector** (database)

   - âœ… Industry-standard relational database
   - âœ… pgvector extension for future semantic search
   - âœ… Strong ACID guarantees
   - âœ… Docker support for easy deployment
   - âœ… SQLAlchemy 2.0 compatibility

2. **SQLAlchemy 2.0** (ORM)

   - âœ… Modern async-capable ORM (using sync mode)
   - âœ… Type-safe queries with new syntax
   - âœ… Relationship management
   - âœ… Migration support via Alembic (future)
   - âœ… Connection pooling built-in

3. **rapidfuzz 3.14.3** (fuzzy matching)

   - âœ… Fast Levenshtein distance calculations
   - âœ… Multiple matching algorithms
   - âœ… Property normalization support
   - âœ… Active maintenance
   - âœ… Pure Python (no C deps)

4. **extract-msg** (vs mail-parser)

   - âœ… Already in requirements.txt
   - âœ… Specifically for Outlook .msg files
   - âœ… Handles RTF, HTML, plain text bodies
   - âœ… Extracts attachments and metadata
   - âŒ mail-parser: Not maintained since 2020, for standard email formats

5. **LangGraph** (vs raw LangChain)

   - âœ… State machine workflow management
   - âœ… Easy node composition
   - âœ… Built-in error handling
   - âœ… Synchronous execution support
   - âœ… Visual workflow representation
   - âœ… Redis caching integration

6. **BeautifulSoup4** (vs regex only)

   - âœ… Robust HTML parsing
   - âœ… Handles malformed HTML
   - âœ… Easy tag removal
   - âœ… Entity decoding
   - âœ… Preserves text content

7. **Pydantic v2** (vs dataclasses)

   - âœ… Runtime validation
   - âœ… JSON serialization
   - âœ… Type coercion
   - âœ… Documentation via models
   - âœ… OpenAPI integration ready

8. **openpyxl** (vs pandas/xlsxwriter)
   - âœ… Pure Python (no external deps)
   - âœ… Rich formatting support
   - âœ… Multiple sheet management
   - âœ… Formula support
   - âœ… Active maintenance

## Workflow Execution Flow

```
1. INITIALIZATION
   â”œâ”€ Load products_config.yaml
   â”œâ”€ Initialize Azure OpenAI client (with Redis caching)
   â”œâ”€ Test database connection (if --match flag)
   â””â”€ Create LangGraph workflow

2. INGESTION PHASE
   â”œâ”€ Scan directory for .msg files
   â”œâ”€ Parse each email (extract-msg)
   â”œâ”€ Validate Email models
   â””â”€ Add to workflow state

3. PREPROCESSING PHASE
   â”œâ”€ Strip HTML tags (BeautifulSoup)
   â”œâ”€ Remove signatures/footers
   â”œâ”€ Clean quoted text
   â””â”€ Update Email.cleaned_body

4. EXTRACTION PHASE (per email)
   â”œâ”€ Build LLM prompt with:
   â”‚  â”œâ”€ Product definitions from config
   â”‚  â”œâ”€ Cleaned email body
   â”‚  â””â”€ Example extractions
   â”œâ”€ Call llm.invoke() - synchronous
   â”œâ”€ Parse JSON response via structured_output
   â”œâ”€ Validate ProductMention models
   â””â”€ Add to state.extracted_products

5. MATCHING PHASE (if --match enabled)
   â”œâ”€ Load inventory items from database
   â”œâ”€ For each extracted product:
   â”‚  â”œâ”€ Filter by category (exact match)
   â”‚  â”œâ”€ Normalize properties (rapidfuzz)
   â”‚  â”œâ”€ Calculate Jaccard similarity scores
   â”‚  â”œâ”€ Rank matches by score
   â”‚  â””â”€ Generate review flags if needed
   â””â”€ Update state with matches and flags

6. PERSISTENCE PHASE
   â”œâ”€ Store emails to emails_processed table
   â”œâ”€ Store products to product_mentions table (FK to emails)
   â”œâ”€ If matching enabled:
   â”‚  â”œâ”€ Store matches to inventory_matches (FK to products & inventory)
   â”‚  â””â”€ Store flags to match_review_flags (FK to products)
   â””â”€ Commit transactions

7. ANALYTICS PHASE
   â”œâ”€ Group products by name/category
   â”œâ”€ Calculate aggregates:
   â”‚  â”œâ”€ Total mentions
   â”‚  â”œâ”€ Date ranges
   â”‚  â”œâ”€ Quantity sums
   â”‚  â””â”€ Property variations
   â””â”€ Create ProductAnalytics models

8. REPORTING PHASE
   â”œâ”€ Create Excel workbook (openpyxl)
   â”œâ”€ Generate Sheet 1: Product Mentions
   â”œâ”€ Generate Sheet 2: Analytics
   â”œâ”€ Generate Sheet 3: Email Summary
   â”œâ”€ If matching enabled:
   â”‚  â”œâ”€ Generate Sheet 4: Inventory Matches (color-coded)
   â”‚  â””â”€ Generate Sheet 5: Review Flags (priority-coded)
   â”œâ”€ Apply formatting and filters
   â””â”€ Save to output directory

9. ERROR HANDLING
   â”œâ”€ Log parsing errors (continue processing)
   â”œâ”€ Record LLM failures
   â”œâ”€ Track validation failures
   â”œâ”€ Database transaction rollbacks
   â””â”€ Generate error report in state
```

## Key Design Decisions Explained

### 1. No Email Threading

**Rationale**: Email thread reconstruction is complex and error-prone:

- Unreliable headers (In-Reply-To, References often missing)
- Subject line matching (RE:, FW: variations)
- Date/time alignment across timezones
- Out of scope for current requirements

**Solution**: Treat each email independently, extract all product mentions per email.

### 2. Synchronous Processing

**Rationale**:

- Simpler debugging and error tracking
- Easier to reason about execution flow
- No concurrency bugs
- Performance adequate for current scale (~10-20 emails/min)

**Trade-off**: Could process faster with async, but added complexity not worth it yet.

### 3. Test-Driven Development

**Rationale**:

- Catch bugs early in email parsing (complex format handling)
- Document expected behavior
- Enable confident refactoring
- Ensure LLM extraction reliability

**Current Coverage**: 26 passing tests across email parsing and signature cleaning.

### 4. Configurable Products

**Rationale**:

- Business requirements change frequently
- Different customers need different product types
- Properties vary by industry
- No code changes needed for new products

**Implementation**: YAML config with product definitions, aliases, and properties.

## Error Handling Strategy

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ERROR CATEGORIES                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚ 1. PARSING ERRORS                                        â”‚
â”‚    â€¢ Corrupted .msg file â†’ Skip file, log error         â”‚
â”‚    â€¢ Missing required fields â†’ Use defaults             â”‚
â”‚    â€¢ Encoding issues â†’ Fallback encoding                â”‚
â”‚                                                          â”‚
â”‚ 2. LLM ERRORS                                            â”‚
â”‚    â€¢ API timeout â†’ Retry 3x with backoff                â”‚
â”‚    â€¢ Invalid JSON â†’ Log, continue with empty result     â”‚
â”‚    â€¢ Rate limiting â†’ Sleep and retry                    â”‚
â”‚                                                          â”‚
â”‚ 3. VALIDATION ERRORS                                     â”‚
â”‚    â€¢ Pydantic validation fail â†’ Log details             â”‚
â”‚    â€¢ Missing required fields â†’ Skip product             â”‚
â”‚    â€¢ Invalid dates â†’ Use None                           â”‚
â”‚                                                          â”‚
â”‚ 4. REPORT GENERATION ERRORS                              â”‚
â”‚    â€¢ Excel write fail â†’ Raise exception (fatal)         â”‚
â”‚    â€¢ Permission denied â†’ Clear error message            â”‚
â”‚                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Performance Characteristics

**Current Benchmarks** (estimated):

- Email parsing: ~100ms per file
- Signature cleaning: ~50ms per email
- LLM extraction: ~2-5 seconds per email (Azure OpenAI latency)
- Excel generation: ~500ms for 100 rows

**Bottleneck**: Azure OpenAI API calls (synchronous)

**Scalability Path** (future):

1. Implement LLM response caching
2. Batch similar emails together
3. Switch to async if needed
4. Consider local LLM for faster processing

## Security Considerations

1. **API Keys**: Stored in `.env` file (gitignored)
2. **Email Content**: Processed locally, not sent to third parties (except Azure OpenAI)
3. **PII Handling**: Email addresses extracted but not filtered
4. **File Permissions**: Excel reports created with user permissions

## Maintenance & Monitoring

**Logging Strategy**:

- Info: Each phase completion
- Warning: Parsing failures (continue processing)
- Error: LLM failures, validation errors
- Debug: Detailed extraction results

**Metrics to Track**:

- Emails processed / failed
- Products extracted per email
- LLM call success rate
- Average processing time

## SQL Chat Workflow Architecture

### Overview

The **SQL Chat Workflow** (`src/chat_workflow/`) provides a natural language interface to query the WestBrand PostgreSQL database. Users can ask questions in plain English, and the system translates them to SQL queries using Azure OpenAI GPT-5.

### Key Components

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   SQL CHAT WORKFLOW                             â”‚
â”‚                  (LangGraph State Machine)                      â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  List    â”‚â†’ â”‚   Get     â”‚â†’ â”‚  Generate   â”‚â†’ â”‚ Execute  â”‚  â”‚
â”‚  â”‚ Tables   â”‚  â”‚  Schema   â”‚  â”‚   Query     â”‚  â”‚  Query   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                       â†‘               â†“         â”‚
â”‚                                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                    (Loop for follow-ups)        â”‚
â”‚                                                                 â”‚
â”‚  State: ChatState (Pydantic v2)                                â”‚
â”‚  â€¢ messages: conversation history (add reducer)                â”‚
â”‚  â€¢ available_tables: discovered table names                    â”‚
â”‚  â€¢ executed_queries: SQL transparency tracking                 â”‚
â”‚  â€¢ query_result: last result from database                     â”‚
â”‚                                                                 â”‚
â”‚  Persistence: PostgreSQL Checkpointer                          â”‚
â”‚  â€¢ Thread-based conversation history                           â”‚
â”‚  â€¢ Survives server restarts                                    â”‚
â”‚  â€¢ Enables multi-turn conversations                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Node Responsibilities

1. **list_tables** (`nodes/list_tables.py`): Discovers available database tables using SQL introspection
2. **get_schema** (`nodes/get_schema.py`): Fetches table schemas (columns, types) as LangChain tool
3. **generate_query** (`nodes/generate_query.py`): LLM-powered natural language to SQL translation with tool binding
4. **execute_query** (`nodes/execute_query.py`): Validates (SELECT only) and executes SQL, generates AI explanations
5. **generate_explanations** (`nodes/generate_explanations.py`): Creates human-readable query explanations and result summaries

### Workflow Execution Flow

```
1. USER INPUT
   â”œâ”€ Natural language question
   â”œâ”€ Thread ID for conversation continuity
   â””â”€ Submit via CLI or REST API

2. LIST TABLES NODE
   â”œâ”€ Query information_schema.tables
   â”œâ”€ Filter to WestBrand tables (emails_processed, product_mentions, etc.)
   â””â”€ Add to state.available_tables

3. GET SCHEMA NODE (Tool)
   â”œâ”€ Called by LLM when needed
   â”œâ”€ Query information_schema.columns for specific table
   â”œâ”€ Return column names, types, constraints
   â””â”€ LLM uses this to build correct SQL

4. GENERATE QUERY NODE
   â”œâ”€ LLM receives:
   â”‚  â”œâ”€ User question
   â”‚  â”œâ”€ Available tables
   â”‚  â”œâ”€ WestBrand domain knowledge (system prompt)
   â”‚  â””â”€ get_schema tool binding
   â”œâ”€ LLM may call get_schema tool multiple times
   â”œâ”€ LLM generates SQL query
   â””â”€ Returns AIMessage with tool_calls

5. EXECUTE QUERY NODE
   â”œâ”€ Extract SQL from tool_calls
   â”œâ”€ Validate: Must be SELECT only (security)
   â”œâ”€ Execute against PostgreSQL
   â”œâ”€ Generate AI explanation and result summary
   â”œâ”€ Add QueryExecution to state.executed_queries
   â””â”€ Return ToolMessage with result

6. GENERATE EXPLANATIONS NODE
   â”œâ”€ Takes all executed queries
   â”œâ”€ Generates one-line explanations (non-technical)
   â”œâ”€ Creates result summaries ("Found 80 records")
   â””â”€ Adds to QueryExecution objects

7. SHOULD_CONTINUE ROUTER
   â”œâ”€ Check last message for tool_calls
   â”œâ”€ If tool_calls â†’ execute_query (loop)
   â”œâ”€ If no tool_calls â†’ generate_explanations (end)
   â””â”€ Enables multi-turn conversations

8. PERSISTENCE
   â”œâ”€ Every state change saved to PostgreSQL
   â”œâ”€ Checkpoint includes full message history
   â”œâ”€ Thread ID links related conversations
   â””â”€ Can resume conversations later
```

### API Interfaces

#### 1. CLI Interface (`cli.py`)

```bash
python -m src.chat_workflow.cli

# Interactive REPL
You: How many emails are in the system?
ğŸ¤– Agent: There are 156 emails in the database.

======================================================================
ğŸ“Š SQL Queries Executed:
======================================================================

Query 1:
  ğŸ’¡ Counts the total number of emails in the database
  ğŸ“ˆ Result: Found 156 records

  SQL:
    SELECT COUNT(*) AS email_count FROM emails_processed;
======================================================================
```

#### 2. REST API (`api.py` - FastAPI)

**Non-Streaming Endpoint:**

```
POST /chat
{
  "message": "How many emails are in the system?",
  "thread_id": "user-123"
}

Response:
{
  "response": "There are 156 emails in the database.",
  "executed_queries": [
    {
      "query": "SELECT COUNT(*) FROM emails_processed;",
      "explanation": "Counts total emails",
      "result_summary": "Found 156 records"
    }
  ]
}
```

**Streaming Endpoint:**

```
POST /chat/stream
Server-Sent Events (SSE):
data: {"type": "token", "content": "There"}
data: {"type": "token", "content": " are"}
data: {"type": "token", "content": " 156"}
data: {"type": "sql", "query": "SELECT COUNT(*)..."}
data: {"type": "done"}
```

### SQL Query Transparency

**Feature**: Every query execution is tracked with AI-generated explanations for full transparency.

**Benefits**:

- Users understand what SQL is being run
- Educational - learn SQL by example
- Debugging - verify query correctness
- Audit trail - track database access

**Implementation** (`QueryExecution` model):

```python
QueryExecution
  â€¢ query: str  # Actual SQL executed
  â€¢ query_explanation: QueryExplanation
    - description: str  # "Counts total emails"
    - result_summary: str  # "Found 156 records"
  â€¢ raw_result: Optional[str]  # Query result
```

### Security Features

1. **Read-Only Access**: Only SELECT queries allowed (validated with regex)
2. **SQL Injection Protection**: Uses psycopg parameterized queries
3. **Error Handling**: Database errors caught and returned as error messages
4. **No DDL/DML**: CREATE, DROP, INSERT, UPDATE, DELETE all blocked

### Conversation Persistence

**PostgreSQL Checkpointer** (`langgraph-checkpoint-postgres`):

- Stores conversation state in `checkpoints` table
- Each message adds a new checkpoint
- Thread ID links related checkpoints
- Enables conversation history retrieval
- Survives server restarts

**Checkpoint Schema**:

```sql
CREATE TABLE checkpoints (
    thread_id TEXT,
    checkpoint_id TEXT PRIMARY KEY,
    parent_checkpoint_id TEXT,
    checkpoint JSONB,  -- Full state snapshot
    metadata JSONB,
    created_at TIMESTAMP DEFAULT NOW()
);
```

### Testing

**Test Coverage** (52/56 tests passing - 93%):

- `test_graph.py`: Workflow state machine tests (3 tests need updates)
- `test_api.py`: FastAPI endpoint tests
- `test_execute_query.py`: SQL execution tests
- `test_list_tables.py`: Table discovery tests
- `test_models.py`: Pydantic model validation tests
- `test_sql_transparency.py`: Query transparency tests (1 test needs update)
- `test_db_wrapper.py`: Database wrapper tests

### Domain Knowledge (System Prompts)

**Custom prompts** (`prompts.py`) include:

- WestBrand database schema context
- Common query patterns (email counts, product mentions, etc.)
- Property extraction logic
- Inventory matching concepts
- Best practices for SQL generation

**Example prompt snippet**:

```
You are a SQL expert helping users query the WestBrand database.

Available tables:
- emails_processed: Email metadata (subject, sender, date)
- product_mentions: Extracted products from emails
- inventory_items: Available inventory with properties
- inventory_matches: Product-to-inventory matches
- match_review_flags: Quality issues with matches

Always use SELECT queries only. Never modify data.
Provide clear explanations for every query.
```

## Future Enhancements (Not in Scope)

1. âŒ Email thread reconstruction (explicitly avoided)
2. âŒ Async processing (not needed yet)
3. âŒ Real-time processing (batch workflow)
4. âœ… **Natural language database interface** (SQL Chat implemented)
5. âœ… **Database storage** (PostgreSQL implemented)
6. âŒ Multi-language support (English only)
7. âŒ Semantic search with pgvector (prepared but not implemented)
8. ğŸ”„ Chat workflow web UI (currently CLI/API only)
9. ğŸ”„ Query result caching
10. ğŸ”„ Multi-database support

## Deployment Requirements

**System Requirements**:

- Python 3.11+
- 4GB RAM minimum (for database + LLM caching)
- 500MB disk space
- Internet connection (Azure OpenAI)
- Docker & Docker Compose (for PostgreSQL)

**Infrastructure**:

- PostgreSQL 17 with pgvector extension
- Redis 7 for LLM response caching
- Docker containers for both services

**Dependencies**: See `requirements.txt` and `pyproject.toml`

Key libraries:

- extract-msg==0.55.0
- beautifulsoup4==4.13.5
- langgraph==1.0.3
- langgraph-checkpoint-postgres==2.0.13
- langchain-openai==1.0.2
- langchain-redis==0.1.6
- pydantic==2.12.4
- openpyxl==3.1.5
- sqlalchemy==2.0.36
- psycopg[binary]==3.2.12
- rapidfuzz==3.14.3
- fastapi==0.115.5
- uvicorn[standard]==0.34.0
- pytest==9.0.1
- pyyaml==6.0.3

## Success Metrics

**Phase 1: Foundation** âœ… COMPLETE

- [x] 128/129 tests passing (99.2%)
- [x] Email parsing working
- [x] Signature cleaning implemented
- [x] Pydantic models defined

**Phase 2: Core Workflow** âœ… COMPLETE

- [x] LangGraph workflow implemented
- [x] Azure OpenAI integration working
- [x] Product extraction functional
- [x] Configuration system complete

**Phase 3: Database & Matching** âœ… COMPLETE

- [x] PostgreSQL database schema
- [x] SQLAlchemy models and operations
- [x] Inventory loader and parser
- [x] Fuzzy property matching
- [x] Product-to-inventory matching
- [x] Review flag generation

**Phase 4: Production Ready** âœ… COMPLETE

- [x] Excel report generation (5 sheets)
- [x] Integration tests passing (8/8)
- [x] End-to-end workflow complete
- [x] Documentation finalized
- [x] Database persistence working

**Phase 5: Deployment** âœ… COMPLETE

- [x] Docker Compose configuration
- [x] Database migration scripts
- [x] Import scripts for inventory
- [x] SQL Chat Workflow with FastAPI
- [x] Natural language database queries
- [x] Conversation persistence via PostgreSQL checkpointer
- [x] Query transparency with AI explanations
- [x] 133/134 tests passing (99.3%)
- [ ] Full inventory import (11,197 items)
- [ ] Production deployment guide

---

**Document Version**: 2.1  
**Last Updated**: November 20, 2025  
**Status**: Production Ready - Core Features Complete + SQL Chat Interface
