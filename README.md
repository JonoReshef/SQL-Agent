# WestBrand Email Analysis System

## Overview

A **production-ready, full-stack** system for analyzing emails (`.msg` files) to extract product mentions, match them against inventory using **database-driven hierarchical filtering**, persist all data to **PostgreSQL**, and generate comprehensive **5-sheet Excel reports**. The system also includes a **natural language SQL chat interface** for querying the database. The system includes:

- **Email Analysis Backend**: Python-based analysis engine using **Azure OpenAI (gpt-5 with low reasoning effort)** orchestrated through **LangGraph** workflows with **fuzzy matching** for inventory reconciliation
- **SQL Chat Backend**: LangGraph-based natural language to SQL translation using **Azure OpenAI (gpt-4.1)** with conversation persistence and query transparency
- **REST API**: FastAPI server with Server-Sent Events (SSE) streaming for real-time chat responses
- **Frontend**: Modern Next.js 14 web interface with TypeScript and Tailwind CSS for interactive SQL chat
- **Infrastructure**: Docker Compose orchestration for PostgreSQL, Redis, backend, and frontend services

## Updated Architecture (November 2025)

### Key Design Decisions

1. **No Thread Reconstruction**: Each `.msg` file is analyzed as a single entity. No email threading or conversation reconstruction is performed.
2. **Synchronous Processing**: All email analysis operations are synchronous (no async/await) for simplicity. LLM calls use `.invoke()` not `.ainvoke()`. FastAPI server uses async for HTTP handling.
3. **Test-Driven Development**: Comprehensive unit and integration tests using `pytest`. Test suite includes 24 test files covering all major components.
4. **Database-First Architecture**: PostgreSQL 17 with content hashing and thread_hash as primary key for deduplication.
5. **Hierarchical Matching**: Database-driven property-based filtering (10-100x faster than linear scan) with fuzzy matching.
6. **Natural Language Database Interface**: SQL chat workflow enables querying the database with plain English questions.

### Technology Stack

| Component              | Technology             | License    | Purpose                                                          |
| ---------------------- | ---------------------- | ---------- | ---------------------------------------------------------------- |
| **Database**           | PostgreSQL 17          | PostgreSQL | Data persistence with pgvector                                   |
| **ORM**                | SQLAlchemy 2.0         | MIT        | Database operations and models                                   |
| **Email Parsing**      | extract-msg            | MIT        | Parse Outlook .msg files                                         |
| **HTML Processing**    | BeautifulSoup4         | MIT        | Strip HTML from email bodies                                     |
| **AI Orchestration**   | LangGraph              | MIT        | State machine workflow                                           |
| **LLM**                | AzureChatOpenAI        | MIT        | Product extraction (gpt-5) & SQL chat (gpt-4.1) via Azure OpenAI |
| **Fuzzy Matching**     | rapidfuzz              | MIT        | Hierarchical inventory matching                                  |
| **Data Models**        | Pydantic v2            | MIT        | Type-safe data structures                                        |
| **Configuration**      | PyYAML                 | MIT        | Product config management                                        |
| **Excel Output**       | openpyxl               | MIT        | Generate Excel reports                                           |
| **Caching**            | Redis                  | BSD        | LLM response caching                                             |
| **API Server**         | FastAPI                | MIT        | REST API with streaming support                                  |
| **Conversation State** | LangGraph Checkpointer | MIT        | Persistent conversation history                                  |
| **Frontend**           | Next.js 14             | MIT        | React-based web UI with TypeScript                               |
| **UI Components**      | Tailwind CSS           | MIT        | Responsive design system                                         |
| **Streaming UI**       | Server-Sent Events     | W3C        | Real-time response streaming                                     |
| **Testing**            | pytest                 | MIT        | Unit & integration tests                                         |

## Project Structure

```
WestBrand/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ products_config.yaml        # Product definitions & hierarchies
â”œâ”€â”€ frontend/                        # Next.js web interface
â”‚   â”œâ”€â”€ app/                        # Next.js app router
â”‚   â”‚   â”œâ”€â”€ chat/                   # Chat page
â”‚   â”‚   â”œâ”€â”€ layout.tsx              # Root layout
â”‚   â”‚   â””â”€â”€ page.tsx                # Home page
â”‚   â”œâ”€â”€ components/                 # React components
â”‚   â”‚   â”œâ”€â”€ ChatInterface.tsx       # Main chat container
â”‚   â”‚   â”œâ”€â”€ ChatSidebar.tsx         # Thread management
â”‚   â”‚   â”œâ”€â”€ ChatMessages.tsx        # Message display
â”‚   â”‚   â”œâ”€â”€ ChatInput.tsx           # Input field
â”‚   â”‚   â””â”€â”€ helpers/                # Helper components
â”‚   â”œâ”€â”€ hooks/                      # Custom React hooks
â”‚   â”‚   â”œâ”€â”€ useChatStream.ts        # SSE streaming logic
â”‚   â”‚   â”œâ”€â”€ useChatThreads.ts       # Thread management
â”‚   â”‚   â””â”€â”€ useLocalStorage.ts      # Local storage wrapper
â”‚   â”œâ”€â”€ lib/                        # Utilities
â”‚   â”‚   â”œâ”€â”€ api.ts                  # API client
â”‚   â”‚   â””â”€â”€ utils.ts                # Helper functions
â”‚   â”œâ”€â”€ types/                      # TypeScript types
â”‚   â”‚   â”œâ”€â”€ interfaces.ts           # Shared interfaces
â”‚   â”‚   â””â”€â”€ server/                 # Auto-generated from API
â”‚   â”œâ”€â”€ Dockerfile                  # Frontend container
â”‚   â”œâ”€â”€ package.json                # npm dependencies
â”‚   â””â”€â”€ README.md                   # Frontend documentation
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ email.py                # Email & EmailMetadata models
â”‚   â”‚   â”œâ”€â”€ product.py              # ProductMention & ProductAnalytics models
â”‚   â”‚   â”œâ”€â”€ inventory.py            # InventoryItem & InventoryMatch models
â”‚   â”‚   â””â”€â”€ workflow.py             # LangGraph state models
â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â”œâ”€â”€ models.py               # SQLAlchemy database models
â”‚   â”‚   â”œâ”€â”€ operations.py           # CRUD operations with upsert
â”‚   â”‚   â”œâ”€â”€ schema.py               # Database initialization
â”‚   â”‚   â””â”€â”€ connection.py           # Database connection management
â”‚   â”œâ”€â”€ analysis_workflow/
â”‚   â”‚   â”œâ”€â”€ graph.py                # LangGraph workflow (renamed from workflow/)
â”‚   â”‚   â””â”€â”€ nodes/
â”‚   â”‚       â”œâ”€â”€ ingestion/          # Load and parse emails
â”‚   â”‚       â”œâ”€â”€ extraction/         # Extract products with LLM
â”‚   â”‚       â”œâ”€â”€ matching/           # Hierarchical inventory matching
â”‚   â”‚       â”‚   â””â”€â”€ utils/
â”‚   â”‚       â”‚       â”œâ”€â”€ hierarchy.py    # Property hierarchy management
â”‚   â”‚       â”‚       â”œâ”€â”€ filtering.py    # Database-driven filtering
â”‚   â”‚       â”‚       â”œâ”€â”€ matcher.py      # Main matching interface
â”‚   â”‚       â”‚       â””â”€â”€ normalizer.py   # Property normalization
â”‚   â”‚       â”œâ”€â”€ persistence/        # Store to database
â”‚   â”‚       â””â”€â”€ reporting/          # Generate 5-sheet Excel
â”‚   â”œâ”€â”€ server/
â”‚   â”‚   â””â”€â”€ server.py               # FastAPI REST API (unified endpoint)
â”‚   â”œâ”€â”€ chat_workflow/
â”‚   â”‚   â”œâ”€â”€ cli.py                  # CLI interface for testing
â”‚   â”‚   â”œâ”€â”€ graph.py                # LangGraph SQL chat workflow (4 nodes)
â”‚   â”‚   â”œâ”€â”€ prompts.py              # System prompts for SQL generation
â”‚   â”‚   â”œâ”€â”€ README.md               # Chat workflow documentation
â”‚   â”‚   â”œâ”€â”€ nodes/
â”‚   â”‚   â”‚   â”œâ”€â”€ enrich_question.py      # Expand user questions
â”‚   â”‚   â”‚   â”œâ”€â”€ generate_query.py       # Natural language to SQL
â”‚   â”‚   â”‚   â”œâ”€â”€ execute_query.py        # SQL execution and tracking
â”‚   â”‚   â”‚   â””â”€â”€ generate_explanations.py # Query explanation generation
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â”œâ”€â”€ db_wrapper.py       # PostgreSQL connection setup
â”‚   â”‚       â””â”€â”€ tools.py            # LangChain tools (run_query, get_schema)
â”‚   â”œâ”€â”€ inventory/
â”‚   â”‚   â”œâ”€â”€ loader.py               # Load inventory from Excel
â”‚   â”‚   â””â”€â”€ parser.py               # Parse inventory with LLM
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”œâ”€â”€ client.py               # Azure OpenAI client wrapper
â”‚   â”‚   â””â”€â”€ extractors.py          # Product extraction logic
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ config_loader.py       # Load YAML configuration
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ server.py              # FastAPI request/response models
â”‚   â”‚   â””â”€â”€ ...                     # Other models
â”‚   â””â”€â”€ main.py                    # CLI entry point for email analysis
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ import_inventory.py        # Import inventory to database
â”‚   â””â”€â”€ setup_database.py          # Initialize database schema
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_msg_reader.py         # Email parsing tests
â”‚   â”œâ”€â”€ test_signature_cleaner.py  # Signature cleaning tests
â”‚   â”œâ”€â”€ test_database.py           # Database operations tests
â”‚   â”œâ”€â”€ test_hierarchy.py          # Property hierarchy tests
â”‚   â”œâ”€â”€ test_matcher.py            # Matching algorithm tests
â”‚   â”œâ”€â”€ test_workflow.py           # Workflow tests
â”‚   â”œâ”€â”€ test_integration.py        # End-to-end tests
â”‚   â””â”€â”€ chat_workflow/
â”‚       â”œâ”€â”€ test_graph.py          # Chat workflow graph tests
â”‚       â”œâ”€â”€ test_models.py         # Pydantic model tests
â”‚       â”œâ”€â”€ test_nodes.py          # Individual node tests
â”‚       â””â”€â”€ test_db_wrapper.py     # Database wrapper tests
â”œâ”€â”€ data/                          # Email .msg files
â”œâ”€â”€ output/                        # Generated Excel reports
â”œâ”€â”€ docker-compose.yml             # Full stack: PostgreSQL + Redis + Backend + Frontend
â”œâ”€â”€ Dockerfile                     # Backend container
â”œâ”€â”€ .env                           # Azure + Database credentials
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ pyproject.toml                 # Project metadata & pytest config
â””â”€â”€ README.md                      # This file
```

## Completed Components âœ…

### 1. Database Layer (`src/database/`)

- âœ… PostgreSQL 17 with pgvector extension
- âœ… SQLAlchemy 2.0 models with foreign key relationships
- âœ… **thread_hash** as primary key for email deduplication
- âœ… **content_hash** columns for all tables (change detection)
- âœ… Upsert operations with proper conflict resolution
- âœ… Database initialization and migration scripts
- âœ… Docker Compose configuration for PostgreSQL + Redis

### 2. Hierarchical Matching System (`src/analysis_workflow/nodes/matching/utils/`)

- âœ… Database-driven property-based filtering (10-100x faster)
- âœ… Property hierarchy loaded from config (cached with `@lru_cache`)
- âœ… Fuzzy matching with rapidfuzz (80% similarity threshold)
- âœ… Progressive filtering with graceful degradation
- âœ… Match scoring with weighted properties
- âœ… Review flag generation for quality issues

### 3. Email Processing (`src/email_processor/`)

- âœ… Parses Outlook `.msg` files using `extract-msg`
- âœ… Extracts metadata (subject, sender, recipients, date)
- âœ… Handles multiple body formats (plain text, HTML, RTF)
- âœ… Strips HTML tags and removes signatures
- âœ… Returns typed `Email` Pydantic models

### 4. Data Models (`src/models/`)

- âœ… `Email` and `EmailMetadata` - Email data structures
- âœ… `ProductMention` and `ProductProperty` - Product extraction
- âœ… `InventoryItem` and `InventoryMatch` - Matching results
- âœ… `ReviewFlag` - Match quality issues
- âœ… `WorkflowState` - LangGraph state management
- âœ… Updated to Pydantic v2 syntax (ConfigDict)

### 5. LangGraph Workflow (`src/analysis_workflow/graph.py`)

- âœ… 5-node workflow: Ingestion â†’ Extraction â†’ Matching â†’ Persistence â†’ Reporting
- âœ… Conditional matching (enabled with --match flag)
- âœ… Redis caching for LLM responses
- âœ… State management with Pydantic models
- âœ… Error accumulation and handling

### 6. Excel Report Generation (`src/analysis_workflow/nodes/reporting/`)

- âœ… 5-sheet Excel reports with openpyxl
- âœ… Conditional formatting (color-coded scores)
- âœ… Frozen headers and auto-filters
- âœ… Match confidence visualization (green/yellow/orange/red)
- âœ… Review flag priority coding

### 7. SQL Chat Workflow (`src/chat_workflow/`)

- âœ… 4-node LangGraph workflow: enrich_question â†’ generate_query â†” execute_query â†’ generate_explanations
- âœ… Question enrichment to expand user queries for better intent understanding
- âœ… Natural language to SQL translation using Azure OpenAI gpt-4.1
- âœ… PostgreSQL checkpointer for conversation persistence (thread-based)
- âœ… Redis caching for LLM responses (reduces redundant API calls)
- âœ… Query transparency: all SQL displayed with AI-generated explanations
- âœ… Multi-query tracking with overall search process summary
- âœ… CLI interface for interactive testing
- âœ… Read-only query validation (SELECT only)
- âœ… Domain-specific system prompts for WestBrand database
- âœ… **anticipate_complexity** parameter for thorough vs. direct analysis

### 8. FastAPI REST API (`src/server/server.py`)

- âœ… Unified REST API endpoint combining email analysis and SQL chat
- âœ… Server-Sent Events (SSE) streaming for real-time responses
- âœ… Non-streaming fallback endpoint for compatibility
- âœ… CORS middleware for frontend integration
- âœ… Conversation history endpoint (`/history/{thread_id}`)
- âœ… Health check endpoint for monitoring
- âœ… Pydantic models for request/response validation
- âœ… Status updates during query processing
- âœ… Query transparency with AI-generated explanations

### 9. Next.js Frontend (`frontend/`)

- âœ… Modern React 18 with TypeScript and Next.js 14
- âœ… Real-time streaming chat interface using Server-Sent Events
- âœ… Multi-thread conversation management
- âœ… SQL query display with syntax highlighting
- âœ… Responsive mobile-first design with Tailwind CSS
- âœ… Local storage for conversation persistence
- âœ… Auto-generated TypeScript types from OpenAPI schema
- âœ… Copy-to-clipboard for SQL queries
- âœ… Delete thread confirmation dialogs
- âœ… Streaming status indicators

### 10. Docker Compose Deployment

- âœ… 4-service architecture: PostgreSQL, Redis, Backend, Frontend
- âœ… Health checks for all services
- âœ… Automatic dependency management
- âœ… Volume persistence for database and cache
- âœ… Network isolation with bridge networking
- âœ… Environment variable configuration
- âœ… Frontend served on port 3000
- âœ… Backend API on port 8000

## Workflow Design

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Configuration Layer                         â”‚
â”‚    products_config.yaml (products, properties, hierarchy)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Database Layer (PostgreSQL)                 â”‚
â”‚  emails_processed | product_mentions | inventory_items       â”‚
â”‚  inventory_matches | match_review_flags                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Input Layer                              â”‚
â”‚      Scan directory â†’ Load .msg files â†’ Parse emails         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              LangGraph Workflow (Synchronous)                â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚Ingestion â”‚â†’ â”‚Extraction â”‚â†’ â”‚Matching*â”‚â†’ â”‚Persistenceâ”‚  â”‚
â”‚  â”‚          â”‚  â”‚           â”‚  â”‚         â”‚  â”‚           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚       â†“                                           â†“         â”‚
â”‚  Parse .msg                                  Store to DB    â”‚
â”‚  Clean HTML                                  (with upsert)  â”‚
â”‚                                                   â†“         â”‚
â”‚                                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚                                         â”‚  Reporting   â”‚    â”‚
â”‚                                         â”‚              â”‚    â”‚
â”‚                                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                              â”‚
â”‚  *Matching node (optional, enabled with --match flag):      â”‚
â”‚   â€¢ Database-driven hierarchical filtering                  â”‚
â”‚   â€¢ Fuzzy property matching with rapidfuzz                  â”‚
â”‚   â€¢ Match scoring and ranking                               â”‚
â”‚   â€¢ Review flag generation                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Output Layer                             â”‚
â”‚              Excel Workbook (5 sheets)                       â”‚
â”‚  1. Product Mentions | 2. Analytics | 3. Email Summary      â”‚
â”‚  4. Inventory Matches* | 5. Review Flags*                   â”‚
â”‚                  (*if --match enabled)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Azure OpenAI Configuration

```python
from langchain_openai import AzureChatOpenAI
import os

llm = AzureChatOpenAI(
    api_key=os.getenv("AZURE_LLM_API_KEY"),
    azure_endpoint=os.getenv("AZURE_LLM_ENDPOINT"),
    azure_deployment="gpt-4.1",  # Using gpt-4.1 deployment
    api_version="2024-08-01-preview",
    verbose=False,
    temperature=0,  # Deterministic for extraction
    reasoning_effort="low",
)
```

### Environment Variables Required

Create a `.env` file:

```bash
# Azure OpenAI
AZURE_LLM_API_KEY=your_api_key_here
AZURE_LLM_ENDPOINT=https://your-endpoint.openai.azure.com/

# PostgreSQL Database
DATABASE_URL=postgresql://westbrand:westbrand_pass@localhost:5432/westbrand_db

# Redis Cache (optional, defaults to localhost)
REDIS_URL=redis://localhost:6379
```

## Product Configuration

Example `config/products_config.yaml`:

```yaml
products:
  - name: 'Fasteners'
    category: 'Fasteners'
    aliases: ['bolts', 'nuts', 'screws', 'washers']
    properties:
      - name: 'grade'
        type: 'string'
        examples: ['2', '5', '8', 'A490']
      - name: 'size'
        type: 'string'
        examples: ['1/2-13', '3/4-10', 'M12']
      - name: 'length'
        type: 'string'
        examples: ['2"', '3 inches', '50mm']
      - name: 'finish'
        type: 'string'
        examples: ['zinc plated', 'galvanized', 'plain']
      - name: 'material'
        type: 'string'
        examples: ['steel', 'stainless', 'brass']

  - name: 'Threaded Rod'
    category: 'Threaded Rod'
    aliases: ['all-thread', 'threaded bar']
    properties:
      - name: 'diameter'
        type: 'string'
      - name: 'length'
        type: 'string'
      - name: 'grade'
        type: 'string'

extraction_rules:
  quantity_patterns:
    - "\\d+\\s*pcs?"
    - "\\d+\\s*pieces?"
    - "\\d+\\s*units?"
  date_formats:
    - '%m/%d/%Y'
    - '%d-%m-%Y'
    - '%B %d, %Y'
```

## Excel Report Structure

### Without --match flag (3 sheets):

#### Sheet 1: Product Mentions

| Product | Category | Properties | Quantity | Unit | Context | Date Requested | Email Subject | Sender | Email Date | File |
| ------- | -------- | ---------- | -------- | ---- | ------- | -------------- | ------------- | ------ | ---------- | ---- |

#### Sheet 2: Analytics

| Product | Category | Total Mentions | First Mention | Last Mention | Total Quantity | Unique Properties |
| ------- | -------- | -------------- | ------------- | ------------ | -------------- | ----------------- |

#### Sheet 3: Email Summary

| Email File | Subject | Sender | Date | Products Mentioned | Has Attachments |
| ---------- | ------- | ------ | ---- | ------------------ | --------------- |

### With --match flag (5 sheets):

#### Sheet 4: Inventory Matches

| Product | Inventory Item # | Description | Match Score | Rank | Matched Props | Missing Props | Reasoning |
| ------- | ---------------- | ----------- | ----------- | ---- | ------------- | ------------- | --------- |

**Color coding**:

- ğŸŸ¢ Green (â‰¥0.8): High confidence matches
- ğŸŸ¡ Yellow (â‰¥0.6): Medium confidence matches
- ğŸŸ  Orange (<0.6): Low confidence matches
- ğŸ”´ Red: NO MATCHES found

#### Sheet 5: Review Flags

| Product | Issue Type | Match Count | Top Confidence | Reason | Action Needed |
| ------- | ---------- | ----------- | -------------- | ------ | ------------- |

**Priority coding**:

- ğŸ”´ Red: High priority (missing critical properties)
- ğŸŸ¡ Yellow: Medium priority (low match scores)
- ğŸŸ  Orange: Low priority (informational)

## Running Tests

```bash
# Activate virtual environment
source .venv/bin/activate

# Run all tests
pytest tests/ -v

# Run specific test file
pytest tests/test_msg_reader.py -v

# Run with coverage
pytest tests/ --cov=src --cov-report=html

# Run only unit tests
pytest tests/ -m unit
```

## Usage

### Full-Stack Deployment (Recommended)

The complete system (PostgreSQL + Redis + Backend + Frontend) can be deployed with Docker Compose:

```bash
# Start all services
docker-compose up -d

# View logs
docker-compose logs -f

# Check service status
docker-compose ps

# Stop all services
docker-compose down
```

**Services:**

- **Frontend**: http://localhost:3000 (Next.js web interface)
- **Backend API**: http://localhost:8000 (FastAPI REST API)
- **PostgreSQL**: localhost:5432 (database)
- **Redis**: localhost:6379 (cache)

### Frontend Web Interface

Access the chat interface at http://localhost:3000:

**Features:**

- Real-time streaming responses
- Multiple conversation threads
- SQL query transparency with syntax highlighting
- Mobile-responsive design
- Local storage for conversation history
- Copy SQL queries to clipboard

**Configuration:**

- Set `NEXT_PUBLIC_API_URL` in `frontend/.env.local` (default: http://localhost:8000)
- Backend must be running for frontend to function

See `frontend/README.md` for detailed frontend documentation.

### Prerequisites (Development)

```bash
# Start Docker containers (PostgreSQL + Redis)
docker-compose up -d

# Verify containers are running
docker ps

# Initialize database schema (first time only)
python scripts/setup_database.py

# Import inventory data (optional, for matching)
python scripts/import_inventory.py
```

### Running Analysis

```bash
# Activate virtual environment
source .venv/bin/activate

# Basic usage without inventory matching (3-sheet Excel)
python -m src.main data/sales@westbrand.ca output/report.xlsx

# With inventory matching (5-sheet Excel with matches and flags)
python -m src.main data/sales@westbrand.ca output/report.xlsx --match

# Process specific subdirectory
python -m src.main data/Sarah@westbrand.ca/Top-of-Information-Store output/sarah_report.xlsx --match

# Use defaults (data/selected â†’ output/report_<timestamp>.xlsx)
python -m src.main --match
```

### SQL Chat Interface

#### Web Interface (Recommended)

Access the chat interface at http://localhost:3000 after starting Docker Compose.

#### CLI Interface (Development/Testing)

Query the WestBrand database using natural language with automatic question enrichment and query transparency:

```bash
# Start the CLI interface
python -m src.chat_workflow.cli
```

#### REST API Endpoints

The backend API (`src/server/server.py`) provides:

**Example Chat Session:**

```
You: How many emails are in the system?

Enriching question...

ğŸ¤– Agent: There are 156 emails in the database.

======================================================================
ğŸ“Š SQL Queries Executed:
======================================================================

Query 1:
  ğŸ’¡ Counts the total number of processed email records
  ğŸ“ˆ Result: Found 156 records

  SQL:
    SELECT COUNT(*) AS email_count FROM emails_processed;

Overall Summary:
Retrieved the total count of emails by querying the emails_processed table.
======================================================================
```

**Key Features:**

- **Question Enrichment**: Automatically expands queries for better understanding
- **Query Transparency**: All SQL displayed with AI explanations
- **Conversation Persistence**: Thread-based history stored in PostgreSQL
- **Redis Caching**: LLM responses cached to reduce costs
- **Read-only Safety**: Only SELECT queries allowed
- **Anticipate Complexity**: Set `anticipate_complexity: true` for thorough analysis (default: false)

#### REST API Endpoints

The backend API (`src/server/server.py`) provides:

**Base URL**: http://localhost:8000

1. **POST /chat/stream** - Streaming chat with Server-Sent Events (SSE)
   - Real-time token streaming
   - Status updates during processing
   - Query transparency with explanations
   - Overall summary at completion

```bash
curl -X POST http://localhost:8000/chat/stream \
  -H "Content-Type: application/json" \
  -d '{
    "message": "How many emails have been processed?",
    "thread_id": "user-123",
    "anticipate_complexity": false
  }'
```

2. **POST /chat** - Non-streaming chat (JSON response)
   - Complete response in single payload
   - All executed queries with explanations
   - Thread-based conversation continuity

```bash
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Show me the top 5 most requested products",
    "thread_id": "user-123",
    "anticipate_complexity": false
  }'
```

3. **GET /history/{thread_id}** - Retrieve conversation history
   - All checkpoints and messages for a thread
   - Metadata and timestamps

```bash
curl http://localhost:8000/history/user-123
```

4. **GET /health** - Health check endpoint

```bash
curl http://localhost:8000/health
```

**Request Parameters:**

- `message` (string, required): User's question
- `thread_id` (string, required): Unique thread identifier for conversation continuity
- `anticipate_complexity` (boolean, optional, default: false):
  - `false`: Direct answers with minimal queries (faster)
  - `true`: Thorough exploratory analysis with more comprehensive queries

**Response Format (Streaming):**

Server-Sent Events with multiple event types:

```javascript
// Status update
data: {"type": "status", "content": "Executing query..."}

// Message chunk
data: {"type": "message", "content": "The database contains 156 emails."}

// Queries with transparency
data: {"type": "queries", "queries": [{"query": "SELECT COUNT(*) FROM emails_processed", "explanation": "Counts total emails", "result_summary": "Found 156 records"}]}

// Overall summary
data: {"type": "summary", "content": "Retrieved email count from database"}

// End of stream
data: {"type": "end"}

// Error (if any)
data: {"type": "error", "content": "Error message"}
```

**Response Format (Non-Streaming):**

```json
{
  "response": "The database contains 156 emails.",
  "thread_id": "user-123",
  "executed_queries": [
    {
      "query": "SELECT COUNT(*) FROM emails_processed",
      "explanation": "Counts the total number of processed email records",
      "result_summary": "Found 156 records"
    }
  ]
}
```

You: Show me the top 5 most requested products

ğŸ¤– Agent: The top 5 most requested products are:

1. Grade 8 Hex Bolts (42 mentions)
2. Threaded Rod (38 mentions)
3. Washers (31 mentions)
4. U-Bolts (27 mentions)
5. Anchor Bolts (23 mentions)

======================================================================
ğŸ“Š SQL Queries Executed:
======================================================================

Query 1:
ğŸ’¡ Gets the top 5 products by mention count with their categories
ğŸ“ˆ Result: Found 5 records

SQL:
SELECT product_name, product_category, COUNT(\*) as mentions
FROM product_mentions
GROUP BY product_name, product_category
ORDER BY mentions DESC
LIMIT 5;

======================================================================

```

See `src/chat_workflow/README.md` and `frontend/README.md` for complete documentation.

## Development Workflow

1. **Write Tests First**: Before implementing any feature, write comprehensive unit tests
2. **Run Tests Frequently**: Execute tests after each change
3. **Keep It Synchronous**: No async code - use `.invoke()` for LLM calls
4. **Single Email Processing**: Each `.msg` file is independent - no threading
5. **Type Safety**: All data uses Pydantic models for validation
6. **Database First**: All operations persist to PostgreSQL with upsert logic

## Current Status

**Production Ready** - Core features complete

### Completed Features âœ…

- âœ… Email parsing and cleaning (extract-msg + BeautifulSoup)
- âœ… LLM-based product extraction (Azure OpenAI gpt-5 with low reasoning effort)
- âœ… Database persistence (PostgreSQL with thread_hash + content_hash)
- âœ… Database-driven hierarchical matching (10-100x faster)
- âœ… Fuzzy property matching (rapidfuzz)
- âœ… Review flag generation (quality assurance)
- âœ… 5-sheet Excel reports (conditional formatting)
- âœ… LangGraph workflow orchestration
- âœ… Redis caching for LLM responses
- âœ… Docker Compose deployment
- âœ… Comprehensive test suite (24 test files covering all components)
- âœ… **SQL Chat Workflow** - Natural language database queries with question enrichment
- âœ… **FastAPI REST API** - Streaming and non-streaming endpoints with SSE
- âœ… **Token-by-token streaming** - LangGraph dual-stream mode with smooth display
- âœ… **Client-side buffering** - requestAnimationFrame loop for consistent 300 chars/sec rendering
- âœ… **Conversation Persistence** - Thread-based chat history in PostgreSQL
- âœ… **Query Transparency** - AI-generated SQL explanations and summaries
- âœ… **Next.js Frontend** - Modern web UI with TypeScript and Tailwind CSS
- âœ… **Server-Sent Events** - Real-time streaming responses with smooth typewriter effect
- âœ… **Docker Compose** - Full-stack deployment with 4 services
- âœ… **Anticipate Complexity** - Toggle between direct and thorough analysis modes

### Known Issues

- None currently - all core features operational

### Future Enhancements

- ğŸ”„ Email linking in reports for source grounding
- ğŸ”„ Web dashboard for reviewing matches interactively (in progress - frontend built)
- ğŸ”„ Semantic search with pgvector
- ğŸ”„ Automated scheduled email scanning
- ğŸ”„ Query result caching in chat workflow
- ğŸ”„ Multi-database support in chat interface
- ğŸ”„ User authentication and authorization for frontend
- ğŸ”„ Export chat history to PDF/markdown
- ğŸ”„ Dark mode for frontend
- âŒ Email thread reconstruction (explicitly out of scope)
- âŒ Async processing (not needed at current scale)

---

**Status**: Production Ready (Full-Stack)
**Version**: 3.1
**Last Updated**: November 26, 2025

## Additional Documentation

- `STREAMING_ARCHITECTURE.md` - **Token-by-token streaming with client-side buffering architecture**
- `docs/` - **Documentation directory with quick references and visual guides**
  - `docs/README.md` - Documentation index and reading guide
  - `docs/STREAMING_QUICK_REFERENCE.md` - Quick reference for streaming
  - `docs/STREAMING_VISUAL_GUIDE.md` - Visual diagrams and timing charts
- `frontend/README.md` - Next.js frontend documentation and development guide
- `src/chat_workflow/README.md` - SQL Chat Workflow detailed documentation
- `src/server/server.py` - FastAPI REST API implementation with streaming
- `ENHANCED_SQL_TRANSPARENCY.md` - SQL transparency feature implementation
- `SQL_TRANSPARENCY_FEATURE.md` - Original transparency feature design
- `ARCHITECTURE.md` - Detailed system architecture
- `DATABASE_FILTERING_IMPLEMENTATION.md` - Hierarchical matching implementation
- `HIERARCHICAL_MATCHING_IMPLEMENTATION.md` - Matching system design
- `CONTENT_HASH_IMPLEMENTATION.md` - Database change detection
```
